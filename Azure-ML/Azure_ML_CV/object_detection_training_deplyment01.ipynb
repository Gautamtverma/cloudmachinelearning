{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# training \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os, time\n",
    "from cvtk.core import Context, ObjectDetectionDataset, TFFasterRCNN\n",
    "from cvtk.utils import detection_utils\n",
    "\n",
    "# Disable printing of logging messages\n",
    "from azuremltkbase.logging import ToolkitLogger\n",
    "ToolkitLogger.getInstance().setEnabled(False)\n",
    "\n",
    "# Initialize the context object\n",
    "out_root_path = \"../../../cvtk_output_400\"\n",
    "Context.create(outputs_path=out_root_path, persistent_path=out_root_path, temp_path=out_root_path)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "# Display the images\n",
    "%matplotlib inline\n",
    "import xml.etree.ElementTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize variables\n",
    "image_folder = r\"../sample_data/\"\n",
    "annotations_dir = \"Annotation_400\"\n",
    "image_subdirectory = 'Data-400'\n",
    "\n",
    "# training parameters\n",
    "score_threshold = 0.0       # Threshold on the detection score, use to discard lower-confidence detections.\n",
    "max_total_detections = 300  # Maximum number of detections. A high value will slow down training but might increase accuracy.\n",
    "\n",
    "# to get good results, use a larger value for num_steps, e.g., 5000.\n",
    "num_steps = 200\n",
    "learning_rate = 0.001 # learning rate\n",
    "\n",
    "\n",
    "# save only while training\n",
    "save_model_path = out_root_path + \"/frozen_model/faster_rcnn_400.model\" # Please save your model to outside of your AML workbench project folder because of the size limit of AML project\n",
    "\n",
    "\n",
    "# set deployment name\n",
    "deployment_name = \"wsdeployment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "listdir = os.listdir(image_folder + annotations_dir)\n",
    "for filename in listdir:\n",
    "    name = image_folder + annotations_dir + '/' + filename\n",
    "    \n",
    "    et = xml.etree.ElementTree.parse(name)\n",
    "    et.write(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 2018-07-25 10:45:42,183 INFO azureml.vision:machine info {\"is_dsvm\": true, \"os_type\": \"Windows\"} \n",
      "F1 2018-07-25 10:45:42,190 INFO azureml.vision:dataset creating dataset for scenario=detection \n",
      "Dataset name: training_dataset\n",
      "Total classes: 10, total images: 400\n",
      "Label-wise object counts:\n",
      "\tLabel basket: 58 objects\n",
      "\tLabel dishwasher: 65 objects\n",
      "\tLabel headboard: 8 objects\n",
      "\tLabel paper towel: 69 objects\n",
      "\tLabel person: 69 objects\n",
      "\tLabel plate: 49 objects\n",
      "\tLabel printer: 67 objects\n",
      "\tLabel remote control: 25 objects\n",
      "\tLabel stuffed animal: 23 objects\n",
      "\tLabel toilet: 68 objects\n",
      "Bounding box width and height distribution:\n",
      "\tBounding box widths  0/5/25/50/75/95/100-percentile: 8/22/52/88/153/300/621 pixels\n",
      "\tBounding box heights 0/5/25/50/75/95/100-percentile: 4/18/50/90/182/290/469 pixels\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "\n",
    "data_train = ObjectDetectionDataset.create_from_dir(dataset_name='training_dataset', data_dir=image_folder,\n",
    "                                                    annotations_dir=annotations_dir, image_subdirectory=image_subdirectory)\n",
    "\n",
    "# Show some statistics of the training image, and also give one example of the ground truth rectangle annotations\n",
    "data_train.print_info()\n",
    "# _ = data_train.images[2].visualize_bounding_boxes(image_size = (10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "\n",
    "my_detector = TFFasterRCNN(labels=data_train.labels, \n",
    "                           score_threshold=score_threshold, \n",
    "                           max_total_detections=max_total_detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(my_detector.class_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorboard --logdir=C:\\Users\\admin-dsvm\\Documents\\cvp_project\\cvtk_output_400\\temp_faster_rcnn_resnet50\\models\\train\n",
      "F1 2018-07-25 10:53:41,187 INFO azureml.vision:Fit starting in experiment 261243702 \n",
      "F1 2018-07-25 10:53:41,188 INFO azureml.vision:model starting trainging for scenario=detection \n",
      "Using existing checkpoint file that's saved at 'C:\\Users\\admin-dsvm\\Documents\\cvp_project\\cvtk_output_400\\models\\detection\\faster_rcnn_resnet50_coco_2018_01_28\\model.ckpt.index'.\n",
      "TFRecords creation started.\n",
      "F1 2018-07-25 10:53:41,194 INFO On image 0 of 400\n",
      "F1 2018-07-25 10:53:41,298 INFO On image 100 of 400\n",
      "F1 2018-07-25 10:53:41,396 INFO On image 200 of 400\n",
      "F1 2018-07-25 10:53:41,496 INFO On image 300 of 400\n",
      "TFRecords creation completed.\n",
      "Training started.\n",
      "Training progressing: step 0 ...\n",
      "Training progressing: step 100 ...\n",
      "F1 2018-07-25 11:32:03,412 INFO Graph Rewriter optimizations enabled\n",
      "Converted 275 variables to const ops.\n",
      "F1 2018-07-25 11:32:10,922 INFO 3159 ops in the final graph.\n",
      "F1 2018-07-25 11:32:24,722 INFO azureml.vision:Fit finished in experiment 261243702 \n",
      "Training completed.\n",
      "2323.5446515083313\n"
     ]
    }
   ],
   "source": [
    "# change steps while training \n",
    "print(\"tensorboard --logdir={}\".format(my_detector.train_dir))\n",
    "\n",
    "\n",
    "\n",
    "start_train = time.time()\n",
    "my_detector.train(dataset=data_train, num_steps=num_steps, \n",
    "                  initial_learning_rate=learning_rate)\n",
    "end_train = time.time()\n",
    "print(end_train-start_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorboard --logdir=C:\\Users\\admin-dsvm\\Documents\\cvp_project\\cvtk_output_400\\temp_faster_rcnn_resnet50\\models\\eval --port=8008\n"
     ]
    }
   ],
   "source": [
    "print(\"tensorboard --logdir={} --port=8008\".format(my_detector.eval_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Step 6: Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 2018-07-25 13:03:40,304 INFO Graph Rewriter optimizations enabled\n",
      "Converted 275 variables to const ops.\n",
      "F1 2018-07-25 13:03:46,152 INFO 3159 ops in the final graph.\n"
     ]
    }
   ],
   "source": [
    "my_detector.save(save_model_path) #(r'C:\\Users\\admin-dsvm\\Documents\\cvp_project\\cvtk_output\\frozen_model\\faster_rcnn_100.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "detections_dict = my_detector.score(r'C:\\Users\\admin-dsvm\\Documents\\cvp_project\\classification\\detection\\sample_data\\Data-100\\1.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04102655, 0.03830199, 0.02843399, 0.02680402, 0.02664556,\n",
       "       0.02293397, 0.02276698, 0.02069485, 0.01996751, 0.01966314,\n",
       "       0.01820783, 0.01810025, 0.0178801 , 0.01693222, 0.01683766,\n",
       "       0.01677918, 0.01664479, 0.01635437, 0.01503515, 0.01488737,\n",
       "       0.01457681, 0.01411349, 0.01401917, 0.01197707, 0.0118463 ,\n",
       "       0.01169397, 0.01147731, 0.01146626, 0.01093624, 0.01065345,\n",
       "       0.01060342, 0.01045635, 0.0100084 , 0.00913158, 0.0090277 ,\n",
       "       0.00900642, 0.00894993, 0.00888191, 0.00886698, 0.00884378,\n",
       "       0.00863337, 0.00852825, 0.00839657, 0.00823467, 0.00816436,\n",
       "       0.00802594, 0.00801599, 0.00756569, 0.00752374, 0.00746532,\n",
       "       0.00746292, 0.00734097, 0.00731743, 0.00709262, 0.0069861 ,\n",
       "       0.00670625, 0.00669661, 0.00654807, 0.00652158, 0.0064776 ,\n",
       "       0.00639548, 0.00635433, 0.00632431, 0.00617288, 0.00616848,\n",
       "       0.00594472, 0.00590741, 0.00581393, 0.00567456, 0.00565433,\n",
       "       0.00562199, 0.00557957, 0.00551915, 0.00548276, 0.00544227,\n",
       "       0.00542604, 0.00537418, 0.00523598, 0.00518705, 0.00507247,\n",
       "       0.00505826, 0.00505352, 0.00503249, 0.00501152, 0.00493562,\n",
       "       0.00492879, 0.00490108, 0.00485001, 0.00484092, 0.00480768,\n",
       "       0.00476805, 0.00473133, 0.00470964, 0.00470498, 0.00466118,\n",
       "       0.00461294, 0.00455297, 0.00449672, 0.00447871, 0.0044642 ,\n",
       "       0.00446366, 0.00446353, 0.004408  , 0.00437922, 0.00437435,\n",
       "       0.00430684, 0.00428829, 0.00427065, 0.00419649, 0.00417012,\n",
       "       0.00416876, 0.00406879, 0.00404843, 0.0040347 , 0.00398282,\n",
       "       0.00396644, 0.0039068 , 0.00386954, 0.00378558, 0.00377544,\n",
       "       0.00372537, 0.00371565, 0.00371008, 0.00370371, 0.00370226,\n",
       "       0.00369572, 0.00367035, 0.00365861, 0.00364891, 0.00362776,\n",
       "       0.00357243, 0.00355182, 0.00350794, 0.00348445, 0.00345644,\n",
       "       0.00343875, 0.00343733, 0.00341962, 0.00339968, 0.00339227,\n",
       "       0.00338271, 0.00338126, 0.00336969, 0.00336514, 0.00336218,\n",
       "       0.00333559, 0.00332909, 0.0032817 , 0.00327826, 0.00327416,\n",
       "       0.00326353, 0.00326302, 0.00326125, 0.00325649, 0.0032402 ,\n",
       "       0.00322672, 0.00321709, 0.00319841, 0.00318693, 0.00317194,\n",
       "       0.00316579, 0.00314583, 0.0031092 , 0.00310519, 0.00308007,\n",
       "       0.00307182, 0.00306304, 0.00306095, 0.00301345, 0.00298818,\n",
       "       0.00297669, 0.00296656, 0.00292217, 0.00288804, 0.00283049,\n",
       "       0.0028246 , 0.00280492, 0.00280025, 0.00278421, 0.00278342,\n",
       "       0.00276144, 0.00273788, 0.00273422, 0.00273048, 0.00271264,\n",
       "       0.00269966, 0.00269874, 0.00269679, 0.00268572, 0.00267971,\n",
       "       0.00262244, 0.00259504, 0.00258612, 0.00256009, 0.00253725,\n",
       "       0.00252447, 0.00252003, 0.00250026, 0.00249027, 0.00248327,\n",
       "       0.0024723 , 0.0024096 , 0.00237793, 0.00236793, 0.00236237,\n",
       "       0.00233612, 0.00232385, 0.00228459, 0.0022796 , 0.00227849,\n",
       "       0.00227527, 0.00227067, 0.00225326, 0.00224749, 0.00224388,\n",
       "       0.0022396 , 0.00222898, 0.0022148 , 0.00217782, 0.00217644,\n",
       "       0.00217297, 0.00214064, 0.00210828, 0.00210045, 0.00209976,\n",
       "       0.00207124, 0.0020617 , 0.00206048, 0.00204278, 0.00203867,\n",
       "       0.00202346, 0.0020164 , 0.00201549, 0.00201326, 0.0020061 ,\n",
       "       0.00199873, 0.00199474, 0.00199071, 0.00197419, 0.00196954,\n",
       "       0.00193802, 0.00192731, 0.00191571, 0.00191332, 0.00190566,\n",
       "       0.00189734, 0.00189464, 0.00188763, 0.00187584, 0.00186621,\n",
       "       0.00185709, 0.00183977, 0.0018381 , 0.00183598, 0.00182338,\n",
       "       0.00182112, 0.00180723, 0.00180237, 0.00179627, 0.0017549 ,\n",
       "       0.00174009, 0.00174006, 0.00172549, 0.00171655, 0.00170734,\n",
       "       0.00169452, 0.0016763 , 0.00166937, 0.00165438, 0.00165412,\n",
       "       0.00163552, 0.0016267 , 0.0016179 , 0.00160724, 0.00159874,\n",
       "       0.00159705, 0.00158595, 0.00156488, 0.00155969, 0.00154977,\n",
       "       0.00154789, 0.00154633, 0.00154151, 0.00153754, 0.00152657,\n",
       "       0.0015132 , 0.00151197, 0.00150284, 0.00149504, 0.00149317,\n",
       "       0.00146489, 0.00145702, 0.00143699, 0.00143526, 0.00142442,\n",
       "       0.00142185, 0.00141907, 0.00141701, 0.00141234, 0.00140647],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detections_dict['detection_scores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_up = dict((v,k) for k,v in my_detector.class_map.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = []\n",
    "for i in range(detections_dict['num_detections']):\n",
    "    if detections_dict['detection_scores'][i] > 0.3:\n",
    "\n",
    "        pred_labels.append(look_up[detections_dict['detection_classes'][i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvtk.operationalization import AMLDeployment\n",
    "\n",
    "\n",
    "\n",
    "# Create deployment object\n",
    "# It will use the current deployment environment (you can check it with CLI command \"az ml env show\").\n",
    "deploy_obj = AMLDeployment(deployment_name=deployment_name, aml_env=\"cluster\", associated_DNNModel=my_detector, replicas=1)\n",
    "\n",
    "# Alternatively, you can provide azure machine learning deployment cluster name (environment name) and resource group name\n",
    "# to deploy your model. It will use the provided cluster to deploy. To do that, please uncomment the following lines to create \n",
    "# the deployment object.\n",
    "\n",
    "# azureml_rscgroup = \"<resource group>\"\n",
    "# cluster_name = \"<cluster name>\"\n",
    "# deploy_obj = AMLDeployment(deployment_name=deployment_name, associated_DNNModel=my_detector,\n",
    "#                            aml_env=\"cluster\", cluster_name=cluster_name, resource_group=azureml_rscgroup, replicas=1)\n",
    "\n",
    "# Check if the deployment name exists, if yes remove it first.\n",
    "if deploy_obj.is_existing_service():\n",
    "    AMLDeployment.delete_if_service_exist(deployment_name)\n",
    "    \n",
    "# create the webservice\n",
    "print(\"Deploying to Azure cluster...\")\n",
    "deploy_obj.deploy()\n",
    "print(\"Deployment DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score with existing deployment object\n",
    "\n",
    "# Score local image with file path\n",
    "print(\"Score local image with file path\")\n",
    "image_path_or_url = data_train.images[0].storage_path\n",
    "print(\"Image source:\",image_path_or_url)\n",
    "serialized_result_in_json = deploy_obj.score_image(image_path_or_url, image_resize_dims=[224,224])\n",
    "print(\"serialized_result_in_json:\", serialized_result_in_json[:50])\n",
    "\n",
    "# Score image url and remove image resizing\n",
    "print(\"Score image url\")\n",
    "image_path_or_url = \"https://cvtkdata.blob.core.windows.net/publicimages/microsoft_logo.jpg\"\n",
    "print(\"Image source:\",image_path_or_url)\n",
    "serialized_result_in_json = deploy_obj.score_image(image_path_or_url)\n",
    "print(\"serialized_result_in_json:\", serialized_result_in_json[:50])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
